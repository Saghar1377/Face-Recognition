{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d15636",
   "metadata": {},
   "outputs": [],
   "source": [
    " import zipfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import tensorly as tly\n",
    "from tensorly.tenalg import mode_dot\n",
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738fb4a",
   "metadata": {},
   "source": [
    "In the first box, I created matrices A for each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = 'archive.zip'\n",
    "\n",
    "desired_size = (192,168)\n",
    "\n",
    "image_data_dict = {}\n",
    "all_images = [] \n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    file_list = zip_ref.namelist()\n",
    "    for file_name in file_list:\n",
    "            subject_id = file_name.split('/')[1].split('_')[0]\n",
    "            image_data = zip_ref.read(file_name)\n",
    "            img = Image.open(io.BytesIO(image_data))\n",
    "            img_resized = img.resize(desired_size)\n",
    "    \n",
    "            img_array = np.array(img_resized).flatten()\n",
    "            all_images.append(img_array)\n",
    "\n",
    "            if subject_id in image_data_dict:\n",
    "                image_data_dict[subject_id]['FlattenedVectors'].append(img_array)\n",
    "            else:\n",
    "                image_data_dict[subject_id] = {\n",
    "                    'FlattenedVectors': [img_array],\n",
    "                }\n",
    "                \n",
    "                \n",
    "matrices_list=[]\n",
    "for subject_id, data in image_data_dict.items():\n",
    "    concatenated_matrix = np.column_stack(data['FlattenedVectors'])\n",
    "    matrices_list.append(concatenated_matrix)\n",
    "    print(f\"matrix for {subject_id}:\\n{concatenated_matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325f61c",
   "metadata": {},
   "source": [
    "In the next boxes, I created the desired tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f80b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resize = (32256,65)\n",
    "resized_matrices = [np.resize(matrix, resize) for matrix in matrices_list]\n",
    "\n",
    "tensor = np.stack(resized_matrices, axis=2)\n",
    "\n",
    "print(\"3-Mode Tensor Shape:\", tensor.shape)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74696ad",
   "metadata": {},
   "source": [
    "Now, we have the tensor and it's time to apply HOSVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1, dim2, dim3 = tensor.shape\n",
    "\n",
    "matrix_1 = tensor.reshape(dim1, -1)\n",
    "F, _, _ = np.linalg.svd(matrix_1, full_matrices=False)\n",
    "\n",
    "matrix_2 = tensor.transpose(1, 0, 2).reshape(dim2, -1)\n",
    "G, _, _ = np.linalg.svd(matrix_2, full_matrices=False)\n",
    "\n",
    "matrix_3 = tensor.transpose(2, 0, 1).reshape(dim3, -1)\n",
    "H, _, _ = np.linalg.svd(matrix_3, full_matrices=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fc0ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nF:\")\n",
    "print(F)\n",
    "print(\"\\nG:\")\n",
    "print(G)\n",
    "print(\"\\nH:\")\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " S = mode_dot(mode_dot(mode_dot(tensor,F.T,0), G.T,1), H.T,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a487dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nS:\")\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd265392",
   "metadata": {},
   "source": [
    "Now, It,s time to do the first approach.\n",
    "First, we create C which is created by multiplying S and F and G and the tensor2 which is created by multiplying C and H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba502f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = tly.tenalg.mode_dot(S, F, mode=0)\n",
    "C = tly.tenalg.mode_dot(C, G, mode=1)\n",
    "tensor2 = tly.tenalg.mode_dot(C, H, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c84b58",
   "metadata": {},
   "source": [
    "for each expression e, we need to minimize ‚Äñùê∂ùëíùõºùëí ‚àí ùëß‚Äñ and z will be the image of the person with the least amount of this norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z is the given image that we want to classify.\n",
    "z = all_images[2]\n",
    "aes = []\n",
    "norms = []\n",
    "\n",
    "for i in range(0,65):\n",
    "    ce = C[ : , i , :]\n",
    "    ae, _, _, _ = lstsq(ce, z)\n",
    "    norm = np.linalg.norm(np.dot(ce,ae) - z) \n",
    "    norms.append(norm)\n",
    "    aes.append(ae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = min(norms)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms.index(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
